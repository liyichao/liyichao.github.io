---
layout: post
title: "spark 容错机制"
category: 
tags: []
---
{% include JB/setup %}


本文介绍 spark 对各个层面的失败的容错机制。

# Task

我们先考虑最底层的失败，某一个 Task 执行失败了。Task 失败由 executor 感知到，通过 statusUpdate 层层传递到 driver 端的 `TaskSetManager.handleFailedTask`，其基本逻辑是：

* 如果是 FetchFailed，即 reduce task 拿不到 shuffle 数据，那么上一个 Stage 需要重跑。（FetchFailed 的处理之后会详讲）
* 如果不是 FetchFailed，并且该 Task 的其他尝试（spark 可能会启动 task 的多个副本）还未成功，会重新启动该 task。
* 当然，重启次数超过 `spark.task.maxFailures`，taskSet 会失败，这意味着一个 stage 失败了。stage 失败整个任务就失败了，spark 会取消该 stage 对应的 job 包含的所有 task，并返回用户任务执行失败。

### FetchFailed

我们来考虑 FetchFailed 的处理，值得注意的是 FetchFailed 的处理会在未来有比较大的变化，见 [SPARK-20178](https://issues.apache.org/jira/browse/SPARK-20178)。

FetchFailed 会在 ShuffleReader 取数据失败 N 次后抛出，然后由 executor 通过 statusUpdate 传到 driver 端，实际的处理会在 `DAGScheduler.handleTaskCompletion`，它会重新提交该 Stage 和该 Stage 对应的 ShuffleMapStage，重试次数超过 `spark.stage.maxConsecutiveAttempts` 时会退出。

从中可见，现在的处理还是比较原始的，更理想的处理方式是：

* 取哪个 ShuffleMapTask 的数据取失败了，只需要重跑该 Task，而不是重跑整个 ShuffleMapStage。
* 对于已经取完该 task 输出的 reduce 任务，不需要重跑
* 对于尚未取该 task 输出的 reduce 任务，可以让它先去取别的 task 返回的数据，轮到该 task 时，可以先暂停，然后由 driver 端在该 task 重试成功后告诉 reduce 任务新的数据的位置，并重启该 task。

### Speculative task

有时候 task 不是失败了，而是太慢了，这时 spark 会多启动几个实例（spark 中一个实例叫 attempt），有任何一个实例成功了该 task 就成功了。spark 会周期性检查是否有 task 符合 speculation 的条件，检查逻辑在 `TaskSetManager.checkSpeculatableTasks`。

那么多个实例如何防止其输出不干扰呢？例如一个实例 A成功了，输出，另一个实例 B成功了，其输出覆盖了 A 的输出，甚至更糟糕的是两者同时写一个文件，导致输出错乱。

有几个层面：

* 首先，输出到文件是通过 `ShuffleWriter.write` 写的。以 `SortShuffleWriter` 为例，最后在 `IndexShuffleBlockResolver.writeIndexFileAndCommit` 里会先写数据到临时文件，然后检查文件是否存在，如果文件不存在，就重命名临时文件为正式文件。
	
	* 如果两个 task attempt 在同一个 executor 执行，这种情况是不可能的，调度时保证两个 attempt 不会运行在同一台机器上，详情见 `TaskSetManager.dequeueSpeculativeTask`（`IndexShuffleBlockResolver`中，检查文件是否存在和文件重命名是在一个 `synchronized` 块里的，这个 `synchronized` 看起来没什么必要）
	* 如果两个 task attempt 在两个 executor 执行，但这两个 executor 在同一台机器上。这种情况在 speculative task 是不可能出现的，这在 speculative task 调度时保证。（不过好像也没事，就是重命名文件时，后面的覆盖前面的，反正内容都一样）
	* 两个 task attempt 在不同机器上运行，这时两台机器上都有输出文件

* 一个 attempt 成功了，会在 `TaskSetManager.handleSuccessfulTask` 中取消其他正在运行的 task 实例。如果在取消前，有另一个 attempt 成功了，那么另一个 attempt 的输出会注册到 mapOutputTracker 里，从而覆盖之前的实例的注册，这点似乎没有处理好，按理，应该在消息传到 driver 时就直接忽略掉。


# Executor


### Executor crash

先考虑 Executor crash 的情况。在 deploy mode 为 spark standalone 情况下，系统实际运行的进程是 `CoarseGrainedExecutorBackend`，所以 Eexecutor crash 就等于该进程 crash。有几个可能会发现：

* `CoarseGrainedSchedulerBackend.onDisconnected` 这是 RPC 系统发现 executor 连不上了，该函数会调用 `removeExecutor`，进而调用 `TaskSchedulerImpl.removeExecutor`。
* Worker 里的 `ExecutorRunner` 会监控 executor 进程，其结束时会发送 `ExecutorStateChanged` 给 Worker，从而到达 Master，最后到达 `CoarseGrainedSchedulerBackend.removeExecutor`。Master 会重启 executor，一个 app 的 executor 重启超过 `spark.deploy.maxExecutorRetries`，app 会被终止。
* sparkContext 里有个 `HeartbeatReceiver`，如果一段时间内没收到 executor 的心跳，会触发 `TaskSchedulerImpl.executorLost`。该函数也会在 `CoarseGrainedSchedulerBackend.removeExecutor` 中被调用。

如果 deploy mode 为 mesos，如果运行模式是 Coarse-Grained（Fine-Grained 已经是 deprecated 的了），实际运行的也是 `CoarseGrainedExecutorBackend`。在该情况下 executor crash 会通过 `MesosCoarseGrainedSchedulerBackend.statusUpdate` 处理，它会从`totalCoresAcquired` 中减去已使用的 cpu，从而在下次调度时，由于 `totalCoresAcquired < spark.cores.max`，会启动一个新的 executor，没有重启次数限制。

executor 挂了，task 会在 TaskSchedulerImpl.removeExecutor 里被标记为失败，而 task 失败的处理上一节介绍过了。

### Executor 网络分区

Executor 网络分区指的是 executor 没有挂，但是和 driver 的网络连接断了，之后可能会恢复。